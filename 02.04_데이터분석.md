# 02.04_데이터분석

# NumPy

Numerical(수치로 나타낸) + Python 

`pip install numpy` 

`import numpy as np`

- (third party) library or package : 남이 짠 코드
- PIP : 패키지 관리자 (범용) - pip 명령은 터미널에서 실행
- import 명령은 파이썬 코드 안에서 실행

Numpy는 대규모 다차원 배열 및 행렬 연산을 위한 고성능 수학 함수와 도구를 제공하는 파이썬 라이브러리이다. 

→ 이런 데이터 구조를 기반으로 **수학 연산, 선형대수, 통계, 변환, 기본적인 수치 계산** 등이 가능하도록 다양한 함수와 도구를 포함하고 있다. 

- 사용하는 이유
    - 대규모 수치 데이터를 빠르고 메모리 효율적으로 처리하기 위해서
    - 파이썬에서 과학적 연산 및 대규모 데이터 처리를 위해 필수적으로 사용되는 라이브러리
    - Colab을 사용할 경우, Numpy가 기본적으로 설치돼 있음.
- NumPy 버전 확인
    - `np.__version__`
    - 노트북에서 PIP를 실행할 때는 !를 앞에 써야한다.

```python
import numpy as np

# 배열 생성
a = np.array([1,2,3,4,5])
print("Numpy Array:" a)

# 출력 예시
Numpy Array: [1,2,3,4,5]
```

- 함수 호출 : ()
- 인수는 [] ← 배열을 인수로 넘김

## 차원(dimension)

- 정의: 사물이나 공간의 크기, 범위, 특징 등을 나타내는 측정 가능한 속성
- 수학에서의 차원: 배열에서 데이터를 구성하는 축(axis)의 개수 (배열의 속성 → 수로 표현가능해야 함)

![array.png](02%2004_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%2019049f33ba5d8077b228fa1fe297a1de/array.png)

| **차원** | **명칭** | **설명** | **예시** |
| --- | --- | --- | --- |
| **0차원** | 스칼라 (Scalar) | 단일 요소를 포함하는 배열로, 하나의 숫자나 문자를 의미합니다. | np.array(42) → 42 |
| **1차원** | 벡터 (Vector) | 하나의 축을 가지며, 리스트 형태로 표현할 수 있는 배열입니다. | np.array([1, 2, 3]) → [1 2 3] |
| **2차원** | 행렬 (Matrix) | 두 개의 축을 가지며, 행(row)과 열(column)로 구성된 구조입니다. | np.array([[1, 2], [3, 4]]) → [[1 2] [3 4]] |
| **3차원** | 텐서 (Tensor) | 세 개의 축을 가지며, 여러 개의 2차원 행렬을 포함하는 구조입니다. | np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]]) |
| **N차원** | N차원 배열 (N-Dimensional Array) | 3차원 이상의 배열로, 여러 개의 축을 포함하는 복잡한 데이터 구조입니다. | np.array(...) (n ≥ 4) |

### 기초 문법

- 넘파이 배열과 파이썬 배열 다름
- NumPy 배열 차원 확인하려면 .ndim 속성을 사용

```python
array = np.array([1,2,3], [4,5,6])
print(array**.ndim**)
#출력값
2

array = np.array(42)
print(array.ndim)
#출력값 
0

tensor = np.array([[[1,2],[3,4]],[[5,6],[7,8]]])
print(array.ndim)
#출력값
3
```

### 차원을 변경하는 방법

1. `reshape()`을 통한 차원 변경
    
    배열의 크기를 유지하면서 차원을 변경할 수 있다. 
    
    데이터의 총 개수를 변경할 수 없으며, reshape()의 인자로 새로운 차원을 지정해야 함.
    
    ```python
    array = np.array([1,2,3,4,5,6])
    reshaped_array = array.reshape(2,3)
    print(reshaped_array)
    print(reshaped_array.ndim)
    
    #출력값
    [[1 2 3]
     [4 5 6]]
    2
    ```
    
2. `newaxis`를 통한 차원 추가
    
    ```python
    vector = np.array([1,2,3])
    expanded_vector = vector[:, np.newaxis]
    print(vector)
    print(expanded_vector)
    print(expanded_vector.ndim)
    
    #출력값
    [1 2 3]
    [[1]
     [2]
     [3]]
    2
    ```
    

## 형태(Shape)

정의: 배열(array)의 각 **차원(axis)별** **요소** 개수를 나타내는 **튜플(tuple)**

![shape.png](02%2004_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%2019049f33ba5d8077b228fa1fe297a1de/shape.png)

차원: 배열이 몇 개의 축(axis)를 가지는지 나타낸다. 

각 차원의 크기: 배열의 **각 축에 존재하는 요소의 개수**를 의미한다. 

- 형태(shape)
    
    ```python
    [
    	[1,2,3]
    	[4,5,6]
    ]
    ```
    
    - (2,3) → [[]] : 대괄호가 2개 depth로 있기 때문에 2차원 & 왼쪽에서 오른쪽으로 3개기 때문에 3개의 열
    
    ```python
    [  [    [1, 2], [3, 4]
      ],
      [    [5, 6], [7, 8]
      ]
    ]
    ```
    
    - (2,2,2) → 2개의 블록, 각 블록에 2개의 행, 각 행에 2개의 열

| **배열 형태** | **예제 코드** | **결과 (.shape)** | **설명** |
| --- | --- | --- | --- |
| 1차원 배열 | np.array([1, 2, 3]) | (3,) | 1차원 배열로, 요소 3개 |
| 2차원 배열 | np.array([[1, 2], [3, 4]]) | (2, 2) | 2차원 배열로, 2개의 행과 2개의 열 |
| 3차원 배열 | np.array([[[1], [2]], [[3], [4]]]) | **(2, 2, 1)** | **3차원 배열로, 2개의 행, 2개의 열, 각 1개 요소** |
| 0차원 배열 | np.array(5) | **()** | **스칼라 값으로 차원이 없음** |

1. **`reshape()`를 사용한 형태 변경**
    
    `reshape()` 메서드를 사용하면 기존 데이터를 유지한 채 새로운 형태로 배열을 변경할 수 있습니다.
    
    단, 새로운 형태의 배열 크기는 원래 배열의 크기와 같아야 합니다.
    
    ```python
    array = np.array([1, 2, 3, 4, 5, 6])
    
    reshaped_array = array.reshape(2, 3)
    print(reshaped_array)
    ```
    

1. **`resize()`를 사용한 형태 변경**
    
    `resize()` 함수는 원본 배열 자체를 변경하며, 필요할 경우 배열을 확장하거나 축소합니다.
    
    ```python
    array = np.array([1, 2, 3, 4])
    array.resize(2, 3)
    print(array)
    ```
    
    like padding..
    

1. **`np.newaxis`를 사용한 차원 추가**
    
    `np.newaxis`를 사용하면 배열에 새로운 차원을 추가할 수 있습니다.
    
    예를 들어, 1차원 배열을 2차원으로 확장할 때 유용합니다.
    
    ```python
    array = np.array([1, 2, 3])
    print(array.shape)
    
    expanded_array = array[:, np.newaxis]
    print(expanded_array.shape)
    ```
    

1. `flatten()`을 사용한 다차원 배열 평탄화
    
    `flatten()` 메서드는 다차원 배열을 **1차원 배열로 변환**하는 데 사용됩니다.
    
    이 메서드는 **새로운 배열을 생성**하며, 원본 배열에는 영향을 주지 않습니다.
    
    ```python
    array = np.array([[1, 2, 3], [4, 5, 6]])
    flattened_array = array.flatten()
    print(flattened_array)
    ```
    

1. **`ravel()`을 사용한 다차원 배열 평탄화 (참조 반환)**
    
    `ravel()` 메서드는 다차원 배열을 **1차원으로 변환**하지만, 원본 배열에 대한 **참조(view)를 반환**합니다.
    
    즉, 반환된 배열을 수정하면 원본 배열도 변경될 수 있습니다.
    
    ```python
    array = np.array([[1, 2, 3], [4, 5, 6]])
    raveled_array = array.ravel()
    print(raveled_array)
    
    # 참조를 통한 원본 변경 확인
    raveled_array[0] = 99
    print(array)
    ```
    
    위 코드에서 `ravel()`을 사용하여 배열을 1차원으로 변환한 후, 반환된 배열의 첫 번째 요소를 수정하면 원본 배열도 변경되는 것을 확인할 수 있습니다.
    
2. **`transpose()`를 사용한 배열 축 전환**
    
    `transpose()` 메서드는 배열의 **차원을 전환**하여 데이터를 새로운 방식으로 재배치할 수 있도록 합니다.
    
    행과 열을 바꾸거나, 다차원 배열의 축 순서를 변경할 수 있습니다.
    
    ```python
    array = np.array([[1, 2, 3], [4, 5, 6]])
    transposed_array = array.transpose()
    print(transposed_array)
    ```
    

얼마나 정확히 표현할거냐 

32bit - 4 bite를 씀. 정수는 많이, 부동소수점을 정밀하게 표현함. 

64bit - 8 bite를 씀. 더 정밀하게 표현 BUT 메모리 더 많이 차지. 

## 데이터 타입(Data Type)

![데이터타입.png](02%2004_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%2019049f33ba5d8077b228fa1fe297a1de/%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%90%E1%85%A1%E1%84%8B%E1%85%B5%E1%86%B8.png)

| **데이터 타입** | **설명** | **예시** |
| --- | --- | --- |
| **정수형 (Integers)** | 부호 있는 또는 없는 정수를 저장하는 타입 | int8, int16, int32, int64, uint8, uint16 |
| **부동소수점형 (Floating Point)** | 소수점을 포함한 숫자를 저장하는 타입 | float16, float32, float64 |
| **복소수형 (Complex Numbers)** | 실수와 허수를 포함한 복소수를 저장하는 타입 | complex64, complex128 |
| **문자열형 (Strings)** | 고정된 길이의 문자열을 저장하는 타입 | str_ 또는 unicode_ |
| **불리언형 (Boolean)** | True 또는 False 값을 저장하는 타입 | bool_ |
| **객체형 (Object)** | 파이썬 객체를 포함할 수 있는 타입 | object_ |
| **유니버설 타입 (Generic)** | 특정 크기에 국한되지 않는 범용 타입 | int_, float_ |
- NumPy에서 제공하는 데이터 타입은 C 언어의 기본 데이터 타입을 기반으로 하며, 일반적인 파이썬의 데이터 타입보다 **메모리 사용량이 적고, 연산 속도가 빠른** 것이 특징입니다.

### 기초 문법

```python
import numpy as np

# 정수형 배열 생성
array = np.array([10, 20, 30])
print(array.dtype)

#출력 결과
int64
```

```python
import numpy as np

# int32 타입의 정수형 배열 생성
int_array = np.array([1, 2, 3], dtype=np.int32)
print(int_array.dtype)

# float64 타입의 부동소수점 배열 생성
float_array = np.array([1.5, 2.3, 3.7], dtype=np.float64)
print(float_array.dtype)

# 문자열 배열 생성
string_array = np.array(["apple", "banana", "cherry"], dtype=np.str_)
print(string_array.dtype)

#출력 결과
int32       # (환경에 따라 다를 수 있음)
float64     # (환경에 따라 다를 수 있음)
<U6         # (최대 6자의 유니코드 문자열)
```

### 데이터 타입 변환

`astype()` 메서드를 사용하여 기존 배열의 데이터 타입을 다른 타입으로 변환할 수 있음

```python
array = **np.array([1, 2, 3], dtype=np.int32**)

# int32 -> float64로 변환
converted_array = array**.astype(np.float64)**
print(converted_array.dtype)

# float64 -> int8로 변환 (데이터 손실 주의)
converted_int_array = **converted_array.astype(np.int8)**
print(converted_int_array.dtype)
```

## 인덱싱(Indexing)

Index는 배열 내 특정 요소의 위치를 나타내는 정수값

Indexing은 배열의 특정 요소에 접근하거나 값을 참조하기 위한 방법

NumPy Indexing 종류

| **종류** | **설명** |
| --- | --- |
| **정수
(Indexing by Integer)** | 개별 요소에 접근할 때 사용되는 가장 기본적인 인덱싱 방법입니다.
배열의 특정 위치를 지정하여 값을 가져오거나 수정할 수 있습니다. |
| **슬라이싱
(Slicing)** | 특정 범위의 요소를 선택할 때 사용되며, start:end:step 형식으로 지정합니다.
원하는 부분만 추출하거나 일정 간격의 데이터를 선택할 수 있습니다. |
| **불리언(Boolean) 인덱싱** | 조건을 만족하는 요소만 선택할 수 있으며, 조건식을 사용하여 필터링할 때 유용합니다. |
| **팬시(Fancy) 인덱싱** | 리스트나 배열을 이용하여 특정 인덱스를 지정하여 여러 요소를 한 번에 선택할 수 있습니다. |

## 연산

배열의 요소가 들어가면 배열의 요소가 나오는 것. 

연산은 배열 간의 **요소별(element-wise) 연산**부터, **축(axis)을 따라 수행되는 연산**, **브로드캐스팅(broadcasting)**과 같은 고급 연산 기법까지 종류가 많습니다.

특징

- 벡터화 지원: 반복문 없이 배열의 모든 요소에 대해 동시에 연산을 수행하므로 코드가 간결하고 실행 속도가 빠름.
- 요소별 연산: 배열의 각 요소에 대해 동일한 연산이 적용되며, 스칼라 값 또는 다른 배열과의 연산이 가능함.
- 다양한 연산 유형 제공: 기본적인 사칙연산부터, 삼각함수, 지수/로그 연산, 비교 및 논리 연산 등 제공
- 브로드캐스팅 기능: 크기가 다른 배열 간의 연산을 자동으로 조정하여 크기를 맞춰 연산할 수 있도록 함
- 배열 축(axis) 기반 연산: 특정 차원(행 또는 열)에 대한 합계, 평균 . 등집계 연산을 지원함

| **연산 유형** | **설명** | **예시 함수** |
| --- | --- | --- |
| **산술 연산
(Arithmetic Operations)** | 배열의 요소별 사칙연산 수행 | +, -, *, /, np.add(), np.subtract() |
| **비교 연산
(Comparison Operations)** | 요소 간 크기 비교 및 불리언 값 반환 | >, <, ==, np.equal(), np.greater() |
| **논리 연산
(Logical Operations)** | 불리언 배열을 대상으로 AND, OR 연산 수행 | np.logical_and(), np.logical_or() |
| **통계 연산
(Statistical Operations)** | 배열의 평균, 최댓값, 최솟값 등 통계적 계산 수행 | np.mean(), np.sum(), np.min(), np.max() |
| **선형대수 연산
(Linear Algebra Operations)** | 행렬 곱, 전치, 행렬식 등 선형대수 계산 | np.dot(), np.linalg.inv(), np.transpose() |
| **브로드캐스팅
(Broadcasting Operations)** | 크기가 다른 배열 간의 연산 지원 | 자동 배열 크기 조정 |

### 1. 요소별 연산

```python
# 배열 생성
a = np.array([1, 2, 3])
b = np.array([4, 5, 6])

# 덧셈, 뺄셈, 곱셈, 나눗셈 연산
print(a + b)
print(a - b)
print(a * b)
print(a / b)
```

### 2. 비교 연산

```python
print(a > 2)    # 출력: [False False  True]
print(a == b)   # 출력: [False False False]
print(a <= 2)   # 출력: [True True False]
```

### 3. 통계 연산

```python
data = np.array([10, 20, 30, 40, 50])

print(np.mean(data))  # 출력: 30.0 (평균)
print(np.median(data)) # 출력: 30.0 (중앙값)
print(np.max(data))   # 출력: 50 (최댓값)
print(np.min(data))   # 출력: 10 (최솟값)
print(np.std(data))   # 출력: 14.142135... (표준편차)
```

### 4. 선형대수 연산

```python
matrix = np.array([[1, 2], [3, 4]])

# 전치 행렬
print(np.transpose(matrix)) 
#출력값
[[1 3]
 [2 4]]

# 행렬 곱 (내적)
vector = np.array([2, 3])
print(np.dot(matrix, vector))
#출력값
[ 8 18]

# 역행렬 계산
inverse = np.linalg.inv(matrix)
print(inverse)
# 출력값
[[-2.   1. ]
 [ 1.5 -0.5]]
```

- `np.transpose()`는 행과 열을 바꿉니다.
- `np.dot()`은 행렬 곱을 수행합니다.
- `np.linalg.inv()`는 행렬의 역행렬을 계산합니다.

### 5. 브로드캐스팅을 활용한 연산

```python
matrix = np.array([[1, 2, 3], [4, 5, 6]])
vector = np.array([1, 2, 3])
matrix + vector
# 출력값
[[ 2  4  6]
 [ 5  7  9]]
```

### 6. 논리 연산

```python
data = np.array([10, 20, 30, 40, 50])
print(np.logical_and(data > 15, data < 45))
print(np.logical_or(data < 15, data > 45))
# 출력값
[False  True  True  True False]
[ True False False False  True]
```

## 유니버셜 함수

유니버셜 함수: 배열의 모든 요소에 동일한 연산을 적용할 수 있는 기능

NumPy에서 유니버셜 함수(Universal  Functions, UFuncs)는 **배열의 각 요소**에 대해 **반복적으로 수행되는 벡터화된** **연산**을 제공하는 함수이다. 

단일 입력(single input) 및 다중 입력(multiple input)을 지원하며, 요소별로 동작하여 효과적인 수학 및 논리 연산

- 단일 입력(single input): 하나의 배열을 입력으로 받아 요소별 연산을 수행한다.
    
    예) np.sqrt(arr) → 배열의 각 요소에 제곱근 연산 수행
    
- 다중 입력(multiple input): 두 개 이상의 배열을 입력으로 받아 요소별 연산을 수행한다.
    
    예) np.add(arr1, arr2) → 두 배열의 요소별 덧셈 수행
    

| **유형** | **설명** | **예제 함수** |
| --- | --- | --- |
| **산술 연산
(Arithmetic Functions)** | 사칙연산 및 수학적 연산 수행 | np.add(), np.subtract(), np.multiply(), np.divide() |
| **삼각 함수
(Trigonometric Functions)** | 삼각 및 역삼각 함수 계산 | np.sin(), np.cos(), np.tan(), np.arcsin() |
| **지수 및 로그 함수
(Exponential and Logarithmic Functions)** | 지수 및 로그 연산 수행 | np.exp(), np.log(), np.log10() |
| **비교 연산
(Comparison Functions)** | 배열 요소 간 비교 연산 수행 | np.greater(), np.less(), np.equal() |
| **논리 연산
(Logical Functions)** | 불리언 논리 연산 수행 | np.logical_and(), np.logical_or(), np.logical_not() |
| **비트 연산
(Bitwise Functions)** | 이진수 기반 비트 연산 수행 | np.bitwise_and(), np.bitwise_or(), np.bitwise_xor() |

**호도법?** 

1: 60 ↔ pi : 180(호도법)

y = sin(x) ⇒ arcsin y = sin-1(y) = x

sin : R → R (공역과 정의역 모두 실수로 만들기 위해, ‘호도법’ 사용)

- 사용하는 이유
    - 반복문 없이 배열의 요소별 연산을 자동화하여 계산 속도를 높이고 메모리 사용을 최적화하기 위해서
    - 배열의 각 요소에 대해 반복적으로 연산을 수행할 수 있도록 최적화된 기능을 제공함.
    - **내부적으로 벡터화(Vectorization)된 연산**을 수행하여 순수 파이썬보다 빠른 성능을 제공하며, 다양한 수학적, 통계적, 논리적 연산을 지원함.

### 기본 문법

```python
result = np.function_name(array)

#다중 입력 및 출력 지원
result = np.function_name(array1, array2, out = **output_array**)
```

- out 매개변수를 사용하면 결과를 새로운 배열이 아닌 기존 배열에 저장할 수 있음.

부동소수점 표현 (e..?

1. 지수 및 로그 연산 

np.exp()

np.log()

np.log10()

***데이터 분석 3대장***

넘파이(ML/DL): 수치 계산 → 파이썬 기반

판다스(DS): 통계 → 파이썬 기반

RDBMS(SQL) → SQL 기반

> *Pandas: 모든 일이 메모리 상에서 일어남. 
RDBMS: 메모리 상에서 X*
> 

- 미리내테크놀로지스와 협업 가능
- functionbly.com/ko

# Pandas

panel : 관찰 대상이 되는 **개체들의 집합** (금융권 용어)

+data : 임의의 형태로 형식화된 **사실이나 개념, 의사, 명령** 등을 사람이나 기계에 의한 처리가 적합하도록 **숫자, 문자, 기호 등으로 나타낸 것**

Pandas는 **구조화된 데이터**의 조작과 분석을 위한 데이터프레임 및 시리즈 객체를 제공하는 파이썬 라이브러리입니다.

Pandas는 다양한 형태의 데이터를 쉽게 조작하고 변환할 수 있으며, 데이터 정리, 필터링, 집계, 시각화 등 광범위한 기능 지원합니다. 

또한, Pandas는 엑셀, CSV, SQL, JSON 등 다양한 데이터 소스와의 호환성을 제공하며, 데이터를 불러오고 저장하는 작업을 간편하게 수행할 수 있습니다. 

f: N → R ⇒ f: 수열(sequence) 

수학에서의 series(급수. ‘+’로 연결) : sum_(k=1)^n a_k = S_n ⇒ lim_(n→♾️) S_n

| **특징** | **설명** |
| --- | --- |
| **데이터 조작 및 변환** | Pandas는 **행과 열**을 기준으로 데이터를 선택, 필터링, 정렬, 집계 및 피벗할 수 있는 다양한 기능을 제공합니다.
또한, 결측치 처리, 중복 제거, 데이터 형 변환 등을 통해 데이터를 정제하고 분석할 수 있도록 도와줍니다. |
| **빠른 연산 속도** | NumPy의 연산 엔진을 기반으로 하여 대규모 데이터에 대한 연산 속도가 매우 빠릅니다.
벡터화 연산을 지원함으로써 반복문을 사용하지 않고도 효율적으로 데이터를 처리할 수 있습니다. |
| **다양한 데이터 소스 지원** | CSV, 엑셀, SQL 데이터베이스, JSON 등의 다양한 파일 형식을 손쉽게 불러오고 저장할 수 있습니다. |
| **데이터 시각화 연동** | Pandas는 **Matplotlib 및 Seaborn** 등의 라이브러리와 원활하게 연동되어 데이터를 시각적으로 표현할 수 있습니다. |
- 피벗
    - 스타트업: 사업 아이템을 바꾸는 것/ 스푼 라디오(휴대폰 배터리 공유 → 인터넷 라디오 방송)
    - Pandas: 데이터를 특정 기준에 따라 **재구성**하는 작업. 행(row) 데이터를 열(column)로 변환하거나, 특정 열의 값을 새로운 차원으로 배치할 수 있다.
- 사용하는 이유
    - Pandas를 사용하는 이유는 데이터를 구조화하여 효과적으로 처리하고 분석할 수 있도록 하기 위해서입니다.
    - Pandas는 데이터 조작과 분석을 손쉽게 수행할 수 있도록 강력한 기능을 제공하는 라이브러리입니다.
    - 방대한 양의 데이터를 효율적으로 처리하고, 직관적인 방식으로 데이터를 변환 및 분석할 수 있습니다.
    - 데이터 분석 과정에서 Pandas는 데이터 로딩, 정제, 탐색, 시각화, 모델링을 위한 필수적인 도구로 사용되며, 대규모 데이터를 처리하면서도 간결한 코드 작성이 가능합니다.

### 사용 예제

```python
data = { # 딕셔너리 (json의 key:value 와 비슷)
	'이름' : ['홍길동', '김철수', '이영희'], # 배열. 값이 꼭 배열일 필요는 없음
	'나이' : [25, 30, 35],
	'도시' : ['서울', '부산', '인천']
} 

df= pd.DataFrame(data) 

# 데이터프레임 출력
print(df)

#출력값 
		이름 나이 도시
0  홍길동 25 서울
1  김철수 30 부산
2  이영의 35 인천
```

## 시리즈(Series)

- 정의: 인덱스를 가지는 1차원 배열 형태의 자료 구조
- Series는 Python의 기본 자료형인 **리스트(list), 딕셔너리(dict), NumPy 배열(ndarray)**과 유사한 형태를 가지지만, **고유한 인덱스**를 통해 각 데이터 요소에 쉽게 접근할 수 있습니다.
- Series는 한 개의 열(column)으로 구성된 데이터로 볼 수 있으며, 각 요소가 **고유한 인덱스**를 가집니다.
- 일반적으로 **숫자형, 문자열, 날짜 데이터** 등을 저장하는 데 사용되며, Pandas의 핵심 데이터 구조인 DataFrame(데이터프레임)의 구성 요소로 활용됩니다.

| **특징** | **설명** |
| --- | --- |
| **인덱스를 기반으로 하는 1차원 구조** | Series는 1차원 데이터로 구성되며, 각 요소는 인덱스를 통해 접근이 가능합니다.
기본적으로 정수형(0부터 시작) 인덱스를 가지지만, 특정한 레이블(문자열, 날짜 등)로 지정할 수도 있습니다. |
| **다양한 데이터 유형 지원** | Series는 정수, 실수, 문자열, 불리언, 날짜 데이터 등 다양한 유형의 데이터를 저장할 수 있습니다.
단일 데이터 타입을 가지지만, dtype=object를 통해 여러 유형을 함께 저장할 수도 있습니다. |
| **유연한 데이터 생성 및 변환** | 리스트, 딕셔너리, NumPy 배열 등을 사용하여 쉽게 Series를 생성할 수 있습니다.
필요한 경우 기존 데이터의 일부를 선택하여 새로운 Series로 변환할 수 있습니다. |
| **벡터 연산 지원** | NumPy와 유사한 벡터 연산이 가능하여, 반복문 없이 빠르게 연산을 수행할 수 있습니다.
요소별 연산이 가능하며, 브로드캐스팅 기능을 지원합니다. |
| **누락된 데이터 처리** | Series는 결측값(NaN)을 자동으로 처리하며, 누락된 데이터를 탐지하고 조작하는 다양한 기능을 제공합니다. |

```python
import pandas as pd

# 리스트를 이용한 Series 생성
series = pd.Series([10, 20, 30, 40], **index=['a', 'b', 'c', 'd']**)

# 요소 접근
print(**series['a']**)

# 구분선
print('---')

# 벡터 연산 적용
print(series * 2)
```

```python
#출력값
10
---
a    20
b    40
c    60
d    80
dtype: int64
```

### Series 생성 방법

```python
# 리스트를 이용한 생성
s1 = pd.Series([1, 2, 3, 4])

# 딕셔너리를 이용한 생성 (인덱스 지정)
s2 = pd.Series({'a': 10, 'b': 20, 'c': 30})

# 인덱스와 함께 생성
s3 = pd.Series([100, 200, 300], index=['x', 'y', 'z'])

# 특정 데이터 타입 지정
s4 = pd.Series([1.5, 2.5, 3.5], dtype='float64')

print(s1)
print(s2)
print(s3)
print(s4)
```

```python
#출력값

0    1
1    2
2    3
3    4
dtype: int64

a    10
b    20
c    30
dtype: int64

x    100
y    200
z    300
dtype: int64

0    1.5
1    2.5
2    3.5
dtype: float64
```

### Series 기본 속성

```python
s = pd.Series([10, 20, 30, 40], index=['a', 'b', 'c', 'd'])

print(s.values)  # Series의 값 출력
print(s.index)   # 인덱스 확인
print(s.dtype)   # 데이터 타입 확인
print(s.shape)   # 크기 확인 (튜플 형식)
print(s.size)    # 요소 개수 확인
s.name = 'Example Series'  # Series의 이름 설정
print(s.name)    # Series의 이름 출력
```

- 출력 결과
    
    ```python
    [10 20 30 40]
    Index(['a', 'b', 'c', 'd'], dtype='object')
    int64
    (4,)
    4
    Example Series
    ```
    

### 결측치 처리

Series는 결측값(Null)을 자동으로 처리할 수 있음

```python
s = pd.Series([1, 2, None, 4])

# 결측치 확인
print(**s.isnull()**)

# 결측치 채우기
s_filled = **s.fillna**(0)
print(s_filled)
```

```python
#출력값

0    False
1    False
2     True
3    False
dtype: bool

0    1.0
1    2.0
2    0.0
3    4.0
dtype: float64
```

## 데이터프레임 (DataFrame)

Pandas에서 데이터 프레임은 행과 열로 구성된 2차원 테이블 형태의 데이터 구조입니다.

### 구성요소

| **요소** | **설명** |
| --- | --- |
| **데이터
(values)** | DataFrame의 핵심 구성 요소로, 실제 데이터가 포함된 부분입니다.
각 열(column)은 개별적인 데이터 타입을 가질 수 있습니다. |
| **열
(column, Series로 구성)** | DataFrame의 열은 Pandas의 Series 객체로 표현되며, **동일한 데이터 타입**을 유지합니다.
각 열에는 이름(레이블)이 할당되어 데이터를 명확하게 식별할 수 있습니다. |
| **행
(row)** | DataFrame의 각 행은 **서로 다른 속성의 데이터를 포함**하며, 고유한 인덱스로 접근할 수 있습니다.
행 단위의 조작 및 필터링이 가능하여 데이터를 효과적으로 가공할 수 있습니다. |
| **인덱스
(index)** | 각 행을 고유하게 식별하는 레이블(기본적으로 0부터 시작)을 가집니다.
필요에 따라 문자열이나 날짜 형식의 인덱스를 사용할 수 있습니다. |

1. 딕셔너리를 이용한 생성
    
    ```python
    data = {'이름': ['홍길동', '김철수', '박영희'],
            '나이': [25, 30, 28],
            '성별': ['남', '남', '여']}
    
    df = pd.DataFrame(data)
    print(df)
    
    #출력값
        이름  나이 성별
    0  홍길동  25  남
    1  김철수  30  남
    2  박영희  28  여
    ```
    
    - 딕셔너리의 키가 열(column) 이름으로 설정되고, 값들이 행(row) 단위로 입력됩니다.
    - 인덱스는 기본적으로 0부터 시작하는 정수형 인덱스가 자동으로 부여됩니다.

1. 리스트를 이용한 생성
    
    ```python
    data = [[1, 2, 3],
            [4, 5, 6],
            [7, 8, 9]]
    
    df = pd.DataFrame(data, **columns=['A', 'B', 'C']**)
    print(df)
    
    #출력값
       A  B  C
    0  1  2  3
    1  4  5  6
    2  7  8  9
    ```
    

1. NumPy를 이용한 생성
    
    ```python
    data = np.array([[10, 20, 30],
                     [40, 50, 60]])
    
    df = pd.DataFrame(data, columns=['X', 'Y', 'Z'])
    print(df)
    
    #출력값
        X   Y   Z
    0  10  20  30
    1  40  50  60
    ```
    

### 기본 속성

```python

print(**df.head**())  # 처음 5개 행 출력
print(**df.tail**())  # 마지막 5개 행 출력
print(**df.shape**)   # 행과 열의 개수
print(**df.columns**)  # 열 이름
print(**df.index**)   # 행 인덱스
print(**df.info()**)  # 데이터프레임 요약 정보
print(**df.describe()**)  # 수치형 데이터의 요약 통계량

# info() 출력값

<class 'pandas.core.frame.DataFrame'>
RangeIndex: 10 entries, 0 to 9
Data columns (total 4 columns):
 #   Column  Non-Null Count  Dtype 
---  ------  --------------  ----- 
 0   이름      10 non-null     object
 1   국어      10 non-null     int64 
 2   영어      10 non-null     int64 
 3   수학      10 non-null     int64 
dtypes: int64(3), object(1)
memory usage: 452.0+ bytes

# describe() 출력값

              국어         영어         수학
count  10.000000  10.000000  10.000000
mean   88.700000  88.500000  91.300000
std     4.854551   3.807887   2.750757
min    78.000000  80.000000  87.000000
25%    86.500000  87.250000  89.250000
50%    89.500000  89.500000  91.500000
75%    91.750000  90.750000  93.750000
max    95.000000  93.000000  95.000000
```

### 데이터 접근

```python
# 특정 열 선택
print(df['이름'])

# 여러 열 선택
print(df[['이름', '나이']])

# 특정 행 선택 (**iloc: 정수 기반 인덱싱**, **loc: 레이블 기반 인덱싱**)
print(df.iloc[0])  # 첫 번째 행
print(df.loc[0])  # 첫 번째 행 (**레이블이 있는 경우**)

# 특정 행과 열 선택
print(df.loc[0, '이름'])
```

### 데이터 수정 및 연산

1. 특정 값 수정

```python
df.loc[0, '국어'] = 92
```

1. 새로운 열 추가

```python
df['국적'] = '한국'

#출력값
     이름  국어  영어  수학  국적
0   홍길동  92  88  95  한국
1   김철수  85  92  87  한국
2   박영희  78  80  91  한국
3   이순신  92  90  94  한국
4   강감찬  88  85  89  한국
5  신사임당  95  93  92  한국
6  율곡이이  89  87  90  한국
7   정약용  91  90  93  한국
8    허준  86  89  88  한국
9  세종대왕  93  91  94  한국
```

1. 기존 열 삭제

```python
df.drop('국적', axis=1, inplace=True)
print(df)
```

1. 새로운 열 생성

```python
df['총점'] = df['국어'] + df['영어'] + df['수학']

#출력값
     이름  국어  영어  수학   총점
0   홍길동  92   88   95  275
1   김철수  85  92  87  264
2   박영희  78  80  91  249
3   이순신  92  90  94  276
4   강감찬  88  85  89  262
5  신사임당  95  93  92  280
6  율곡이이  89  87  90  266
7   정약용  91  90  93  274
8    허준  86  89  88  263
9  세종대왕  93  91  94  278
```

1. 조건에 따른 데이터 추출

```python
high_korean = df[df['국어'] >= 90]

#출력값
     이름  국어  영어  수학   총점
0   홍길동  92  88  95  275
3   이순신  92  90  94  276
5  신사임당  95  93  92  280
7   정약용  91  90  93  274
9  세종대왕  93  91  94  278
# -> 그 전 index 그대로 가져옴. (reindex 되지 않음)
```

### 데이터 정렬

1. 특정 열 기준 오름차순

```python
df_sorted_math = df.sort_values(by='수학')

#출력값
     이름  국어  영어  수학   총점
1   김철수  85  92  87  264
8    허준  86  89  88  263
4   강감찬  88  85  89  262
6  율곡이이  89  87  90  266
2   박영희  78  80  91  249
5  신사임당  95  93  92  280
7   정약용  91  90  93  274
3   이순신  92  90  94  276
9  세종대왕  93  91  94  278
0   홍길동  92  88  95  275
```

1. 특정 열 기준 내림차순

```python
df_sorted_name = df.sort_values(by='이름', ascending=False)

#출력값
     이름  국어  영어  수학   총점
0   홍길동  92  88  95  275
8    허준  86  89  88  263
7   정약용  91  90  93  274
3   이순신  92  90  94  276
6  율곡이이  89  87  90  266
5  신사임당  95  93  92  280
9  세종대왕  93  91  94  278
2   박영희  78  80  91  249
1   김철수  85  92  87  264
4   강감찬  88  85  89  262
```

### 그룹화

```python
df['성별'] = ['남', '남', '여', '남', '남', '여', '남', '남', '남', '남']
gender_mean = df.**groupby**('성별')['국어'].mean()

#출력값
성별
남    89.5
여    86.5
Name: 국어, dtype: float64
```

## 필터링(filtering)

### 필터링 방법

1. 불리언 인덱싱을 사용한 필터링
    
    ```python
    # 나이가 30 이상인 행 필터링
    print(df[df['나이'] >= 30])
    print('\n')
    
    # 점수가 85점 이상인 행 필터링
    print(df[df['점수'] >= 85]
    ```
    
2. 논리 연산자를 사용한 다중 조건 필터링
    
    ```python
    # 나이가 30 이상이고 점수가 80점 초과인 데이터 필터링
    print(df[(df['나이'] >= 30) & (df['점수'] > 80)])
    print('\n')
    
    # 도시가 '서울'이거나 점수가 90 이상인 데이터 필터링
    print(df[(df['도시'] == '서울') | (df['점수'] >= 90)])
    print('\n')
    
    # 나이가 40 이하가 아닌 데이터 필터링 (NOT 연산)
    print(df[~(df['나이'] <= 40)])
    ```
    
3. `query()`를 사용한 필터링
    
    ```python
    # 점수가 85보다 높은 데이터 필터링
    print(df.query('점수 > 85'))
    print('\n')
    
    # 나이가 30 이상이고 도시가 '부산'인 데이터 필터링
    print(df.query('나이 >= 30 and 도시 == "부산"'))
    ```
    
4. `isin()`을 사용한 필터링
    
    ```python
    # 도시가 '서울' 또는 '부산'인 데이터 필터링
    print(df[df['도시'].isin(['서울', '부산'])])
    print('\n')
    
    # 특정 이름만 포함하는 데이터 필터링
    print(df[df['이름'].isin(['김철수', '이순신'])])
    ```
    
5. 문자열 필터링(str.contains() 활용)
    
    ```python
    # 이름에 '김'이 포함된 행 필터링
    print(df[df['이름'].str.contains('김')])
    print('\n')
    
    # 도시 이름이 '부'로 시작하는 데이터 필터링
    print(df[df['도시'].str.startswith('부')])
    ```
    
6. 조건에 따른 새로운 열 추가
    
    apply()를 사용하여 조건에 따라 새로운 열을 추가할 수 있음. 
    
    ```python
    # 점수가 90 이상인 경우 '합격', 그렇지 않으면 '불합격' 추가
    df['합격여부'] = df['점수'].apply(**lambda** x: '합격' if x >= 90 else '불합격')
    ```
    
7. 결측치(NaN) 필터링 
    
    ```python
    # 결측치가 있는 데이터 찾기
    print(df[df['점수'].isnull()])
    print('\n')
    
    # 결측치가 없는 데이터만 선택
    print(df[df['점수'].notnull()])
    ```
    

## 그룹화(Grouping)

Pandas에서 Grouping(이하 그룹화)은 데이터를 **특정 기준에 따라 그룹화**하여 **집계, 변환, 필터링** 등의 연산을 수행하는 기능을 말합니다.

그룹화는 “분할-적용-결합(Split-Apply-Combine)” 패턴을 따른다.

![split-apply-combine.png](02%2004_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%2019049f33ba5d8077b228fa1fe297a1de/split-apply-combine.png)

```python
# 예제 데이터 생성
data = {
    '이름': ['홍길동', '김철수', '박영희', '이순신', '강감찬', '신사임당'],
    '부서': **['영업', '영업', '인사', '인사', 'IT', 'IT'**],
    '급여': [5000, 5500, 4800, 5100, 6000, 6200]
}

df = pd.DataFrame(data)

# 부서별 급여 평균 계산
grouped = df.**groupby('부서')**['급여'].mean()
print(grouped)
```

```python
#출력값

부서
IT    6100.0
영업    5250.0
인사    4950.0
Name: 급여, dtype: float64
```

- `df.groupby('부서')`: `df` 데이터프레임에서 `'부서'` 열을 기준으로 데이터를 그룹화합니다. 같은 부서에 속한 행들이 하나의 그룹으로 묶입니다.
- `['급여'].sum()`: 그룹화된 각각의 부서에 대해 `'급여'` 열의 값을 합산합니다. 즉, 같은 부서의 급여 값들을 더한 결과를 반환합니다.

### 여러 열을 기준으로 그룹화

```python
grouped = df.groupby(['부서', '이름'])['급여'].sum()
```

```python
부서  이름  
IT  강감찬     6000
    신사임당    6200
영업  김철수     5500
    홍길동     5000
인사  박영희     4800
    이순신     5100
Name: 급여, dtype: int64
```

- `df.groupby(['부서', '이름'])`: 데이터프레임 `df`에서 `'부서'`와 `'이름'` 두 개의 열을 기준으로 데이터를 그룹화합니다.
    - 그룹화 결과는 다중 인덱스(MultiIndex)를 가지며, 같은 부서와 같은 이름을 가진 행들이 하나의 그룹으로 묶입니다.
- `['급여'].sum()`: 그룹별 `'급여'` 값을 합산합니다. 같은 부서 내에서 동일한 이름을 가진 사람의 급여를 합산하여 반환합니다.

### 그룹별 여러 개의 집계 연산 적용

```python
grouped = df.groupby('부서')['급여'].**agg**(['sum', 'mean', 'max', 'min'])
```

```python
      sum    mean   max   min
부서                           
IT  12200  6100.0  6200  6000
영업  10500  5250.0  5500  5000
인사   9900  4950.0  5100  4800
```

### 그룹화 후 필터링

```python
# 급여 합계가 10000 이상인 그룹만 선택
filtered = df.groupby('부서').filter(lambda x: x['급여'].sum() > 10000)
```

```python
     이름  부서    급여
0   홍길동  영업  5000
1   김철수  영업  5500
4   강감찬  IT  6000
5  신사임당  IT  6200
```

### 그룹별 변환 (Transformation)

그룹화된 데이터에서 각 행을 그룹의 기준값으로 변환할 수 있습니다.

```python
df['급여_평균'] = df.groupby('부서')['급여'].transform('mean')
```

```python
     이름  부서    급여   급여_평균
0   홍길동  영업  5000  5250.0
1   김철수  영업  5500  5250.0
2   박영희  인사  4800  4950.0
3   이순신  인사  5100  4950.0
4   강감찬  IT  6000  6100.0
5  신사임당  IT  6200  6100.0
```

- `df.groupby('부서')['급여'].transform('mean')`: 각 부서별 급여 평균을 계산하고, 해당 부서의 모든 행에 적용합니다. 원래 데이터프레임의 크기를 유지하면서 평균 급여 값을 추가합니다.

to be continue…

## 병합(Merging)

Pandas에서 Merging(병합)은 여러 데이터프레임을 공통 열 또는 인덱스를 기준으로 결합하는 과정을 말합니다.

| **병합 유형** | **설명** |
| --- | --- |
| **Inner Join (내부 조인)** | 두 데이터프레임의 공통된 키 값을 기준으로 병합하며, 일치하는 값만 포함합니다. |
| **Outer Join (외부 조인)** | 모든 데이터를 유지하며, 일치하지 않는 값은 NaN으로 표시됩니다. |
| **Left Join (왼쪽 조인)** | 첫 번째(왼쪽) 데이터프레임의 모든 데이터를 유지하며, 일치하는 값이 없는 경우 NaN을 채웁니다. |
| **Right Join (오른쪽 조인)** | 두 번째(오른쪽) 데이터프레임의 모든 데이터를 유지하며, 일치하는 값이 없는 경우 NaN을 채웁니다. |

### 기본 문법

```python
# 기본 문법
pd.merge(left, right, how='병합 방식', on='기준 열')

#예시
df1 = pd.DataFrame({'고객ID': [1, 2, 3],
                    '이름': ['홍길동', '김철수', '이영희']})

df2 = pd.DataFrame({'고객ID': [2, 3, 4],
                    '구매액': [10000, 20000, 30000]})
```

### 1. 내부 조인 (Inner Join)

```python
   고객ID   이름    구매액
0     2  김철수  10000
1     3  이영희  20000
```

### 2. 외부 조인 (outer Join)

```python
   고객ID   이름      구매액
0     1  홍길동      NaN
1     2  김철수  10000.0
2     3  이영희  20000.0
3     4  NaN  30000.0
```

### 3. 왼쪽 조인 (left Join)

```python
   고객ID   이름      구매액
0     1  홍길동      NaN
1     2  김철수  10000.0
2     3  이영희  20000.0
```

### 4. 오른쪽 조인 (right Join)

```python
   고객ID   이름    구매액
0     2  김철수  10000
1     3  이영희  20000
2     4  NaN  30000
```

### 5. 여러 열을 기준으로 병합

```python
df1 = pd.DataFrame({'고객ID': [1, 2, 3],
                    '이름': ['홍길동', '김철수', '이영희'],
                    '도시': ['서울', '부산', '대전']})

df2 = pd.DataFrame({'고객ID': [2, 3, 4],
                    '도시': ['부산', '대전', '광주'],
                    '구매액': [10000, 20000, 30000]})

result = pd.merge(df1, df2, **on=['고객ID', '도시'**], how='inner')
```

```python
   고객ID   이름  도시    구매액
0     2  김철수  부산  10000
1     3  이영희  대전  20000
```

- 두 개 이상의 열을 기준으로 병합하여 동일한 `고객ID`와 `도시`가 모두 일치하는 경우에만 데이터를 병합합니다.

### 6. 인덱스를 기준으로 병합

인덱스를 기준으로 병합하려면 `left_index=True` 또는 `right_index=True` 옵션을 사용합니다.

```python
pd.merge(df1, df2, left_index=True, right_index=True, how='outer')

    이름      구매액
1  홍길동  15000.0
2  김철수      NaN
3  박영희  25000.0
4  NaN  30000.0
```

### 7. 병합 후 열 이름 변경

```python
df1 = pd.DataFrame({'고객ID': [1, 2], '이름': ['홍길동', '김철수'], '구매액': [20000, 30000]})
df2 = pd.DataFrame({'고객ID': [1, 2], '이름': ['박영희', '이순신'], '구매액': [40000, 50000]})

result = pd.merge(df1, df2, on='고객ID', suffixes=('_기존', '_신규'))
```

```python
   고객ID 이름_기존  구매액_기존 이름_신규  구매액_신규
0     1   홍길동   20000   박영희   40000
1     2   김철수   30000   이순신   50000
```

## 결측치 처리(Missing Data)

결측치 처리를 사용하는 이유는 데이터 분석의 정확성과 신뢰성을 확보하기 위해서입니다·

데이터 분석 및 머신러닝에서 데이터의 품질은 분석 결과의 정확성과 직결됩니다.

⇒ 전처리 뿐만 아니라 학습, 추론 때 필요함. 

### 1. 결측치 확인

```python
# 예제 데이터프레임 생성
data = {'이름': ['홍길동', '김철수', np.nan, '이영희'],
        '나이': [25, np.nan, 30, 28],
        '성별': ['남', '남', '여', np.nan]}

df = pd.DataFrame(data)

# 결측치 확인
print(df.isnull())  # 각 요소의 결측 여부 (True: 결측치, False: 정상 값)
print('\n')

print(df.isnull().sum())  # 열별 결측치 개수 확인
print('\n')

print(df.info())  # 데이터 요약 정보로 결측치 확인
```

```python
      이름     나이     성별
0  False  False  False
1  False   True  False
2   True  False  False
3  False  False   True

이름    1
나이    1
성별    1
dtype: int64

<class 'pandas.core.frame.DataFrame'>
RangeIndex: **4 entries**, 0 to 3
Data columns (total 3 columns):
 #   Column  Non-Null Count  Dtype  
---  ------  --------------  -----  
 0   이름      **3 non-null**      object 
 1   나이      **3 non-null**      float64
 2   성별      **3 non-null**      object 
dtypes: float64(1), object(2)
memory usage: 228.0+ bytes
```

### 2. 결측치 제거

결측치가 포함된 행이나 열을 삭제할 수 있으며, 특정 열에서만 결측치를 제거하는 것도 가능하다. 

```python
# 결측치가 포함된 행 삭제
df_dropped_rows = df.dropna()
print(df_dropped_rows)
print('\n')

# 특정 열에서 결측치가 포함된 행만 삭제
df_dropped_subset = df.dropna(subset=['이름'])
print(df_dropped_subset)
print('\n')

# 결측치가 포함된 열 삭제
df_dropped_cols = df.dropna(axis=1)
print(df_dropped_cols)
```

```python
    이름    나이 성별
0  홍길동  25.0  남

    이름    나이   성별
0  홍길동  25.0    남
1  김철수   NaN    남
3  이영희  28.0  NaN

Empty DataFrame
Columns: [] # 다 날라감..
Index: [0, 1, 2, 3]
```

### 3. 결측치 대체

결측치를 특정 값으로 대체하거나, 통계적 방법을 이용해 대체할 수 있습니다.

```python
# 특정 값으로 대체
df_filled_value = df.fillna(value={'이름': '없음', '나이': '없음', '성별': '없음'})
print("특정 값으로 대체:")
print(df_filled_value)
print('\n')

# 평균값으로 대체
df['나이'] = df['나이'].fillna(df['나이'].mean())
print("평균값으로 대체:")
print(df)
print('\n')

# 이전 값으로 대체
df_filled_forward = df.ffill()
print("이전 값으로 대체 (ffill):")
print(df_filled_forward)
print('\n')

# 이후 값으로 대체
df_filled_backward = df.bfill()
print("이후 값으로 대체 (bfill):")
print(df_filled_backward)
```

```python
특정 값으로 대체:
    이름    나이  성별
0  홍길동  25.0   남
1  김철수    없음   남
2   없음  30.0   여
3  이영희  28.0  없음

평균값으로 대체:
    이름         나이   성별
0  홍길동  25.000000    남
1  김철수  27.666667    남
2  NaN  30.000000    여
3  이영희  28.000000  NaN

이전 값으로 대체 (ffill):
    이름         나이 성별
0  홍길동  25.000000  남
1  김철수  27.666667  남
2  김철수  30.000000  여
3  이영희  28.000000  여

이후 값으로 대체 (bfill):
    이름         나이   성별
0  홍길동  25.000000    남
1  김철수  27.666667    남
2  이영희  30.000000    여
3  이영희  28.000000  NaN
```

- `df.fillna(value={'이름': '없음'})`: 각 열의 결측치를 **지정한 값으로** 채웁니다.
- `df['나이'].fillna(df['나이'].mean())`: `'나이'` 열의 결측치를 **평균값으로** 채웁니다.
- `df.ffill()`: 결측치를 **이전 행의 값**으로 채웁니다. (앞방향 채우기)
- `df.bfill()`: 결측치를 **다음 행의 값**으로 채웁니다. (뒤방향 채우기)

### 4. 결측치가 있는 행 필터링

```python
# 예제 데이터프레임 재생성
data = {'이름': ['홍길동', '김철수', np.nan, '이영희'],
        '나이': [25, np.nan, 30, 28],
        '성별': ['남', '남', '여', np.nan]}

df = pd.DataFrame(data)

# 결측치가 없는 행만 추출
df_no_missing = df[df['이름'].notnull()]
print(df_no_missing)
print('\n')

# 특정 열 기준으로 결측치 여부 확인 후 필터링
df_filtered = df[df['성별'].isnull()]
print(df_filtered)
```

```python
    이름    나이   성별
0  홍길동  25.0    남
1  김철수   NaN    남
3  이영희  28.0  NaN

    이름    나이   성별
3  이영희  28.0  NaN
```

- `df[df['이름'].notnull()]`: `'이름'` 열이 **결측치가 아닌** 행만 선택합니다.
- `df[df['성별'].isnull()]`: `'성별'` 열이 **결측치인** 행만 선택합니다.

## 피벗(Pivot)

Pandas에서 피벗은 데이터를 특정 기준에 따라 재구성하여 요약 통계를 계산하고, 행과 열을 재배치하여 보다 쉽게 분석할 수 있도록 하는 과정을 말합니다.

![피벗.png](02%2004_%E1%84%83%E1%85%A6%E1%84%8B%E1%85%B5%E1%84%90%E1%85%A5%E1%84%87%E1%85%AE%E1%86%AB%E1%84%89%E1%85%A5%E1%86%A8%2019049f33ba5d8077b228fa1fe297a1de/%E1%84%91%E1%85%B5%E1%84%87%E1%85%A5%E1%86%BA.png)

### 구성 요소

| **구성 요소** | **설명** |
| --- | --- |
| **인덱스(index)** | 새로운 행 인덱스를 설정할 열을 지정합니다. |
| **열(columns)** | 새로운 열로 설정할 기존 열을 지정합니다. |
| **값(values)** | 행과 열 조합에 해당하는 값으로 사용할 데이터를 지정합니다. |

### Pandas의 피벗 방식

| **방식** | **설명** |
| --- | --- |
| **pivot() 함수** | 고유한 키 조합이 있는 경우에 사용하며, 중복된 값이 있으면 오류가 발생합니다.
주로 데이터를 정렬하고 시각적으로 변환할 때 사용됩니다. |
| **pivot_table() 함수** | 중복된 값이 있을 경우 집계함수를 적용하여 데이터를 요약할 수 있도록 합니다.
평균, 합계, 개수 등의 통계 처리가 가능하며, 피벗보다 더 유연한 기능을 제공합니다. |

피벗을 사용하는 이유는 데이터를 특정 기준에 따라 재구성하여 **의미 있는 패턴을 발견하기 위해서**입니다.

*인간은 시각에 많이 의존. 데이터는 ‘보려고 하는 것’. 어떤 기준이냐에 따라서 무엇이 보이는지가 달라짐.* 

데이터는 단순히 보관하는 것만으로는 의미가 없으며, 이를 목적에 맞게 재구성하고 시각적으로 직관적인 형태로 만들어야 한다. 

Pandas의 `pivot()` 메서드를 사용하면 데이터프레임을 특정 열을 기준으로 **재구성**할 수 있습니다.

```python
# 샘플 데이터 생성
data = {
    '날짜': ['2024-01-01', '2024-01-01', '2024-01-02', '2024-01-02'],
    '제품': ['A', 'B', 'A', 'B'],
    '판매량': [100, 200, 150, 250]
}

df = pd.DataFrame(data)

# 피벗 적용
df_pivot = df.pivot(index='날짜', columns='제품', values='판매량')
print(df_pivot)
```

```python
제품            A    B
날짜                  
2024-01-01  100  200
2024-01-02  150  250
```

- 여러 열을 피벗하기

```python
df_pivot = df.pivot(index=['날짜', '카테고리'], columns='제품', values='판매량')
```

```python
제품                   A      B
날짜         카테고리              
2024-01-01 가전      NaN  200.0
           전자    100.0    NaN
2024-01-02 가전      NaN  250.0
           전자    150.0    NaN
```

- 결측치 처리

```python
df_pivot_table = df.pivot_table(index='날짜', columns='제품', values='판매량', **aggfunc='sum', fill_value=0**)
print(df_pivot_table)
```

```python
제품            A    B
날짜                  
2024-01-01  100  200
2024-01-02  150  250
```

- 여러 값 피벗하기

```python
df_pivot = df.pivot(index='날짜', columns='제품', values=['판매량', '이익'])
```

```python
            판매량       이익    
제품            A    B   A   B
날짜                          
2024-01-01  100  200  20  50
2024-01-02  150  250  30  60
```

- 특정 함수 적용(aggfunc)

```python
df_pivot_table = df.pivot_table(index='날짜', columns='제품', values='판매량', aggfunc=['sum', 'mean'])
```

```python
            sum        mean       
제품            A    B      A      B
날짜                                
2024-01-01  100  200  100.0  200.0
2024-01-02  150  250  150.0  250.0
```

## 중복 제거(Duplicates Removal)

### 1. 데이터프레임에서 중복 제거

```python
# 샘플 데이터 생성
data = {
    '이름': ['홍길동', '김철수', '홍길동', '이영희'],
    '나이': [25, 30, 25, 28],
    '성별': ['남', '남', '남', '여']
}

df = pd.DataFrame(data)

# 중복 제거
df_unique = df.drop_duplicates()
print(df_unique)
```

```python
    이름  나이 성별
0  홍길동  25  남
1  김철수  30  남
3  이영희  28  여
```

### 2. 특정 열을 기준으로 중복 제거

```python
df_unique_name = df.drop_duplicates(subset=['이름'])
```

```python
    이름  나이 성별
0  홍길동  25  남
1  김철수  30  남
3  이영희  28  여
```

### 3. 중복된 행에서 특정 값 유지

```python
# 첫 번째 값을 유지 (기본값)
df_first = df.drop_duplicates(keep='first')

# 마지막 값을 유지
df_last = df.drop_duplicates(keep='last')

# 중복된 모든 값 삭제
df_none = df.drop_duplicates(keep=False)
```

```python
    이름  나이 성별
0  홍길동  25  남
1  김철수  30  남
3  이영희  28  여

    이름  나이 성별
1  김철수  30  남
2  홍길동  25  남
3  이영희  28  여

    이름  나이 성별
1  김철수  30  남
3  이영희  28  여
```

### 4. 원본 데이터 수정

```python
data = {
    '이름': ['홍길동', '김철수', '홍길동', '이영희'],
    '나이': [25, 30, 25, 28],
    '성별': ['남', '남', '남', '여']
}

df = pd.DataFrame(data)

df.drop_duplicates(inplace=True)
```

```python
    이름  나이 성별
0  홍길동  25  남
1  김철수  30  남
3  이영희  28  여
```

### 5. 중복 확인

`duplicated()` 메서드를 사용하여 중복된 행을 확인할 수 있습니다.

```python
data = {
    '이름': ['홍길동', '김철수', '홍길동', '이영희'],
    '나이': [25, 30, 25, 28],
    '성별': ['남', '남', '남', '여']
}

df = pd.DataFrame(data)

df['중복여부'] = df.duplicated()
```

```python
    이름  나이 성별   중복여부
0  홍길동  25  남  False
1  김철수  30  남  False
2  홍길동  25  남   True
3  이영희  28  여  False
```

### 6. 특정 조건을 만족하는 중복 제거

```python
df_unique_multi = df.drop_duplicates(subset=['이름', '나이'])
```

- `이름`과 `나이` 열을 조합하여 중복을 판별하고 제거합니다.

### 7. 중복된 데이터 개수 확인

```python
duplicate_count = df.duplicated().sum()
```

```python
중복된 행 개수: 1
```

### 8. 중복 제거 후 데이터 저장

```python
df_unique.to_csv('unique_data.csv', index=False)

df_new = pd.read_csv('unique_data.csv')
```

## 문자열 처리(String Operations)

블라블라ㅏ…

Alex 교안

https://iasandcb.netlify.app/site/tech/kdt-pangyo-ai-2/2025-02-04

### 한 줄 정리

- 넘파이: 다차원 배열을 연산하기 위한 함수를 제공하는 파이썬 라이브러리
    - 차원(Dimenstion): 데이터가 N개의 축(axis)를 가지는 것.
    - (넘파이) 형태(Shape): 각 축에 몇개의 요소가 있는지 나타내는 것.
    - (일반) 인덱스(Index): 배열에서 특정 요소를 가리키는 것
    - (넘파이) 유니버셜 함수: 배열 간 수학적, 논리적 연산을 할 수 있게 한 함수
- Pandas: 데이터 조작과 분석을 위해 데이터프레임을 제공하는 파이썬 라이브러리
    - 시리즈: 데이터프레임을 구성하는 기본 단위로, 인덱스를 가지는 1차원 배열
    - 데이터프레임: 행과 열로 구성된 2차원 자료구조
    - 피벗: 데이터프레임을 특정 열을 기준으로  index, columns, values를 지정해 재구조화하는 것.
    - Grouping(그룹화): 데이터프레임을 특정 기준에 따라 연산하는 것.
    - Merging(병합): 데이터프레임을 특정 열 또는 인덱스를 기준으로 합치는 것.