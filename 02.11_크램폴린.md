# 02.11_크램폴린


---

### 로컬, VM 기반의 배포 (컨테이너 X)

- VM(virtual machine) = 물리적 컴퓨터를 **소프트웨어로 모사한 가상의 컴퓨터**로, 컴퓨터 시스템의 가상화 또는 에뮬레이션

스프링 부트? 웹 프로그램(웹 애플리케이션)을 쉽고 빠르게 만들 수 있도록 도와주는 자바의 웹 프레임워크 → 3.x

우분투? 데비안 리눅스를 기반으로 개발되며, 데비안에 비해 ‘사용자 편의성’에 초점을 맞춘 리눅스 배포판. → 20.04

JAVA? 객체 지향적 프로그래밍 언어. 처음에는 가전제품 내에 탑재해 동작하는 프로그램을 위해 개발되었지만 현재 웹 애플리케이션 분야에 가장 많이 사용하는 언어 중 하나이고, 안드로이드를 비롯한 모바일 기기용 소프트웨어 개발에도 널리 사용되고 있다. → 17.x.x

라이브러리의 버전을 바꾸면, 이에 따라 패키지와 OS의 버전 또한 업그레이드 해야하는 경우가 생김. 패키지와 OS 버전을 바꾸는 것은 side effect가 크게 발생할 수 있는 사건. 

⇒ 이렇게 하나 업데이트하면 연쇄적으로 버전 이슈 발생할 수 있는 문제. 따라서 컴퓨터에 앱을 올려서 배포하진 않음. 대신 호스트OS 위에 vm 띄워서 필요한 Guest OS와 패키지 설치해서 실행하게 됨. 여러 개 앱 실행해야 한다면 각 앱마다 필요한 게 달라서, vm 띄워서 각 앱을 실행하게 된다. 

### 컨테이너 기반의 배포

‘종속된 기술을 제공한다’

1. 각각의 서비스를 격리된 환경에서 배포할 수 있다. 
2. VM에 비해 **더 가볍게 가상화**를 할 수 있다. 
3. 유연하게 확장이 가능하다. 

### 쿠버네티스의 역할 (컨테이너 관리) - 앱 개발시 템플릿 제공

1. 컨테이너는 유연한 확장을 가능하게 한다. 
2. 쿠베네티스는 컨테이너를 활용하는 다양한 배포 및 운영 기법을 자동화한다. 
    
    → 컨테이너의 유연한 특징을 최대한 활용해서 리소스를 절약하고 서비스를 안정적으로 운영할 수 있다. 
    

### 쿠버네티스 기본 개념

노드 1개 - 서버 1개

- 파드(Pod): **쿠버네티스의 가장 작은 컴퓨팅 단위**
- 레플리카셋(**rs** = ReplicaSet): **다수의 Pod를 관리**
    
    → AutoScaler와 함께 사용하면 복제본 개수를 자동 조절
    
- 디플로이먼트(Deployment): **파드를 새로운 버전으로 업데이트**
    
    = 버전 1 앱이 있고, 버전2 앱이 있으면 image를 build하게 됨. 새로운 버전에 맞는 환경과 패키지가 들어가게 됨. ‘업데이트’는 기존 것을 날려버리고, 새로운 것을 넣는 작업. 
    
    다양한 배포 방식 지원 (Recreate, RollingUpdate, …)
    
- 서비스 (Service): Pod 그룹에 트래픽을 분산해서 전달

![스크린샷 2025-02-11 오후 11.32.19.png](02%2011_%E1%84%8F%E1%85%B3%E1%84%85%E1%85%A2%E1%86%B7%E1%84%91%E1%85%A9%E1%86%AF%E1%84%85%E1%85%B5%E1%86%AB%2019749f33ba5d8010aceecab5b66d27ef/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-02-11_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_11.32.19.png)

IaC(Infra as Code): 모든 쿠버네티스 오브젝트들은 코드로 작성된다. 

→ 편리하게 재현하고 구축하는 게 가능하다. 

- Docker란? 애플리케이션 구축, 구현 및 테스트를 위해 격리된 가상화 환경을 생성하는 서비스형 플랫폼.
- Docker는 컨테이너 엔진으로 리눅스 커널 기능을 사용하여 운영 체제 위에 컨테이너를 만들고, **Docker 자체는 서비스의 컨테이너를 관리하는 데몬으로 실행**된다.
- Docker image란? 애플리케이션을 포장 및 전송하기 위해 도커는 “docker image”를 사용한다. Docker image는 파일로 **애플리케이션 실행에 필요한 독립적인 환경을 포함하며, 런타임 환경을 위한 일종의 템플릿**이다.
- 도커 이미지는 소스 코드, 라이브러리, 종속성, 도구 및 응용 프로그램을 실행하는데 필요한 기타 파일을 포함하는 불변(변경 불가) 파일이다.
- 이러한 일관성은 도커의 큰 특징 중 하나로, 개발자가 안정적이고 균일한 조건에서 소프트웨어를 테스트하고 실험할 수 있도록 한다.

→ 컨테이너를 생성하는 것은 다른 환경과 분리시킨 환경을 만든다는 말이고, 컨테이너를 구동하는 것은 분리된 프로세스화하여 특정 환경을 만드는 것이다. 

---

### 크램폴린 IDE

기획 의도: 보다 편리하고 쉽게 카카오 자원에 기반한 배포를 할 수 있게 만들기 위해. 

크램폴린 IDE 사용 플로우 

1. 크램폴린 IDE를 이용해서 **애플리케이션을 개발한다**. 
(작업 환경: 컨테이너, 터미널 등. 앱 실행해볼 수 있음)
2. 해당 애플리케이션을 **도커 이미지로 빌드하는 Dockerfile**을 작성한다. 
    
    {Gemfile, Gemfile.lock, app.rb} + Dockerfile = Docker Image
    
    #**Dockerfile을 포함한 전체 프로젝트를 github에 올린다.** 
    
3. **D2Hub 레포지토리**에 **이미지를 빌드 및 업로드**한다. 
    
    ⇒ D2Hub에서 이미지를 받아서 여러 개의 컨테이너를 실행할 수 있게 됨. 
    
4. **애플리케이션 이미지 배포**를 위한 **쿠버네티스 yaml 파일을 작성**한다. 
    1. 디플로이먼트(Deployment)는 파드와 레플리카셋(ReplicaSet)에 대한 선언적 업데이트를 제공한다. 
    2. 서비스(Service)는 쿠버네티스에서 네트워크를 통해 Pod 그룹을 노출하는 데 도움이 되는 추상화 방법이다. (서비스를 통해 트래픽이 주어짐)
5. **Kargo**를 통해 **DKOS 클러스터**에 **D2Hub 이미지를 배포**한다. 

크램폴린 IDE로 앱 개발 → 도커 이미지로 빌드하는 **Dockerfile 작성** → **D2Hub에 업로드** → 앱 이미지 배포를 위한 **쿠버네티스 yaml file 작성** → (Kargo를 통해) **DKOS 클러스터에 이미지 배포**

추가 안내사항

- 커밋은 main 브랜치에 작성
- github 소스 코드 상에 변경 사항이 발생하면
    
    커밋 실행 후 d2hub 재빌드 → kargo 재배포
    
- 크램폴린 IDE 개발 환경은 인당 1개씩 생성 가능
- DB는 쿠버네티스 구성 안에서 해주세요. 
(DKOS를 카카오에서 실제로 사용하다보니 보안이 까다로움)

### 실습 step1

크램폴린 IDE를 이용해서 어플리케이션을 배포하기 위해서는 Dockerfile과 쿠버네티스 구성 파일들이 소스 코드에 포함되어 있어야 한다. 

- [D2Hub를 활용한 이미지 빌드 - 1. Dockerfile 생성](https://krampoline-help.goorm.io/ide/kakao-cloud/d2hub/1.-dockerfile)
    
    **프로젝트를 Docker 이미지로 Build하기 위해서는** *이미지 구성 파일*인 **Dockerfile이 필요**합니다.
    D2Hub에서는 *github 소스 저장소의 루트 디렉토리*에 있는 **Dockerfile을 찾아서** **도커 빌드를 시도**합니다.
    
    따라서 **프로젝트 루트 디렉토리에 이미지 빌드를 위한 Dockerfile을 작성한 뒤, 해당 내용을 github 소스 저장소 상에 push** 해야 합니다.
    
- [Kargo App 배포 - 1. Kargo 배포 구성 파일 작성](https://krampoline-help.goorm.io/ide/kakao-cloud/kargo-app/1.-kargo)
    
    Kargo를 이용한 앱 배포 시 github 소스 저장소의 **main 브랜치**에 저장된 소스 코드에서
    
    **쿠버네티스 리소스 구성 파일**을 읽어옵니다. 구성파일의 경우 프로젝트 루트 디렉토리의
    
    **k8s 폴더** 하위에 위치해야 합니다.
    
    Kargo에서는 k8s 폴더 하위의 kustomization.yaml 파일을 참고합니다. kustomization.yaml에서는 k8s 폴더에 함께 있는 구성 파일들을 참조하도록 작성할 수 있습니다. 
    
    <aside>
    💡
    
    kustomization.yaml의 작성 예시는 아래와 같습니다.
    k8s 폴더에 함께 있는 구성 파일들(nginx.yaml, mariadb.yaml, backend.yaml, frontend.yaml)을 참조하고 있습니다.
    
    ```jsx
    namespace: default
    resources:
      - nginx.yaml
      - mariadb.yaml
      - backend.yaml
      - frontend.yaml
    ```
    
    </aside>
    
    *각각의 쿠버네티스 구성 파일 작성 시 D2Hub 이미지 경로를 사용해서 작성해야 합니다. 
    
    ```jsx
    **krmp-d2hub-idock.9rum.cc/dev-test/repo_d6dce6ccda23**
    ```
    
    이를 이용하여 쿠버네티스 구성 파일을 작성합니다. 이미지 경로의 경우 보통 구성 파일의 deployment 객체에 작성합니다. **D2Hub 이미지 경로를 이용한 deployment 객체 작성 예시**는 아래와 같습니다. (위 구성 예시에서는 frontend.yaml 또는 backend.yaml 파일에 작성합니다.)
    
    ```jsx
    apiVersion: apps/v1
    kind: Deployment
    spec:
        template:
            metadata:
                labels:
                    app: **backend**
            spec:
                containers:
                    - name: backend
                      # 여러분의 image 주소를 입력해주세요.
                      image: **krmp-d2hub-idock.9rum.cc/dev-test/repo_d6dce6ccda23**
                      imagePullPolicy: Always
                      ports:
                          - containerPort: **8080**
    ```
    
    또한 이후 단계에서 **배포된 앱에 연결된 외부 접속 URL을 발급하기 위해서는 Ingress 객체에 대한 정의가 필요**합니다. Ingress 객체의 IP에 외부 접속 URL을 연결하게 됩니다. 
    
    Ingress 객체의 작성 예시는 다음과 같습니다. 
    
    ```jsx
    apiVersion: networking.k8s.io/v1beta1
    kind: Ingress
    metadata:
      annotations:
        nginx.ingress.kubernetes.io/ssl-redirect: "false"
      labels:
        **app.kubernetes.io**/managed-by: **kargocd**
      name: krampoline
      namespace: default
    spec:
      rules:
        - http:
            paths:
              - backend:
                  serviceName: krampoline
                  servicePort: **3000**
                  path: /
                  pathType: Prefix
    ```
    
    작업을 모두 마쳤다면 github 소스 저장소의 main 브랜치에 push 합니다. 
    

**Dockerfile**에는 python으로 구성된 server 어플리케이션을 빌드할 수 있는 구성 정보가 작성돼 있습니다. 

```jsx
# Python 3.6 이미지를 기반으로 함
# FROM python:3.6-slim
FROM krmp-d2hub-idock.9rum.cc/goorm/python:3.6-slim

# 작업 디렉토리 설정
WORKDIR /app

# 필요한 Python 스크립트를 이미지에 추가
COPY index.py /app/

# 서버가 실행될 때 사용되는 포트
EXPOSE **3000**

# 컨테이너를 시작할 때 Python 스크립트를 실행
CMD ["python", "/app/index.py"]
```

*⇒ 소스 코드 내에 존재하는 index.py를 docker image 내의 workding directory로 옮기고, 해당 파일을 Python으로 실행하는 커맨드를 설정하는 간단한 Dockerfile 입니다.* 

**D2Hub에서는 github 소스저장소 상의 소스코드를 읽어서, 소스 코드 내의 Dockerfile을 바탕으로 Docker 이미지를 D2Hub Repository에 빌드하고 업로드합니다.** 

*k8s 폴더에는 Kargo 배포를 위한 쿠버네티스 구성 파일들이 위치해있습니다. 

![스크린샷 2025-02-12 오후 2.56.28.png](02%2011_%E1%84%8F%E1%85%B3%E1%84%85%E1%85%A2%E1%86%B7%E1%84%91%E1%85%A9%E1%86%AF%E1%84%85%E1%85%B5%E1%86%AB%2019749f33ba5d8010aceecab5b66d27ef/%E1%84%89%E1%85%B3%E1%84%8F%E1%85%B3%E1%84%85%E1%85%B5%E1%86%AB%E1%84%89%E1%85%A3%E1%86%BA_2025-02-12_%E1%84%8B%E1%85%A9%E1%84%92%E1%85%AE_2.56.28.png)

kustomization.yaml 파일에서는 k8s 폴더 하위에 있는 deployment.yaml, service.yaml, ingress.yaml 파일을 사용하도록 설정돼 있습니다. 

해당 파일들의 내용을 바탕으로 쿠버네티스 리소스 구성이 이루어집니다. 

```jsx
namespace: krampoline
resources:
  - deployment.yaml
  - service.yaml
  - ingress.yaml
```

---

- deployment.yaml 에서는 해당 이미지를 이용해서 app krampoline이라는 라벨을 이용해서 deployment 객체를 구성
- service.yaml에서는 해당 앱 크램폴린 pod들에 대해서 **외부 pod와 내부 타겟 pod를 정의**해주고 있음.
- ingress.yaml에서 받아서(?) 넘겨주고 있는데, path에 오게 되면, **kramploine이라는 서비스로 넘겨준다는 것.**
    
    *ingress.yaml가 krampoline에 3000번 port를 주게되면 → service.yaml가 3000번 port로 받아서, targetport 3000으로 자기의 pod들을 뿌려주는데, 이 pod들은 deployment.yaml에 의해서 관리된다*
    
    *index.py를 보면 3000번 port로 실행하고 있으므로, 최종적으로 연결이 되는 것.* 
    

### 실습 step2

> step2의 소스 코드는 React를 이용한 간단한 Frontend App을 배포할 수 있는 코드로 구성돼 있습니다. 
3000번 포트로 요청을 보내면 React로 구성한 웹 페이지를 보여주는 어플리케이션입니다. 
*step2의 소스코드에 대한 자세한 설명은 Step2 소스 코드 설명 강의에서 확인할 수 있습니다.*
> 

`krampoline-step2`은 krampoline의 React 예제입니다. 이 저장소에서는 `create-react-app`를 사용하여 기본적인 **React App**을 만듭니다. [serve](https://www.npmjs.com/package/serve)를 이용하여 3000번 포트에서 서버를 열고 React 기본 파일을 제공합니다. (Dockerfile)

- k8s 폴더는 step2파일(프론트엔드)만 실행했을 때, 실행할 수 있게 넣어놓은 거고, 전체적으로 실행할 때는 setp4에 있는 k8s 폴더를 사용할 것.

![image.png](02%2011_%E1%84%8F%E1%85%B3%E1%84%85%E1%85%A2%E1%86%B7%E1%84%91%E1%85%A9%E1%86%AF%E1%84%85%E1%85%B5%E1%86%AB%2019749f33ba5d8010aceecab5b66d27ef/image.png)

→ 기본적인 frontend 코드들. 

STEP3

> step3의 소스 코드는 Spring을 이용한 간단한 Backend Server를 도커 이미지로 빌드할 수 있는 코드로 구성돼 있습니다.
> 

*Dockerfile 보면, jdk 이미지를 기반으로 하고 있고, 디렉토리 설정 후에 Spring 코드를 가져와서, gradle을 이용해서 빌드한 다음에, db 값을 환경 변수로 삽입하고, 실행 CMD를 정해야 함.* 

STEP4

> step4는 기본적으로 mariaDB 이미지.
> 

*굳이 따로 도커파일 작성할 필요 없는 파일이긴 한데, 이런 식으로도 배포 가능하다는 것을 보여주기 위함.* 

step2 레포지토리 빌드 후 이미지 경로를 복사해서 step4의 k8s의 frontend.yaml 파일에 가서 이미지 주소에 넣어줌. step3, step4도 마찬가지. 

→ Step4에 모든 yaml 파일들을 넣어놨기 때문에, step4를 이용해서 Kargo app을 만들면 됨. 

teminal에 `kubectl get pod` 하면 현재 실행중인 pod 확인 가능. 

`kubectl get deploy` 하면 정의했던 backend, frontend, deployment 확인 가능. 

`kubectl delete deploy (deployment명)` 하면 deployment 삭제 가능. 

`kubectl get statefulset` or `kubectl get sts` 하면 DB가 뜸. 

`kubectl describe sts mariadb` 하면 자세한 정보 볼 수 있음. 

`kubectl get pvc` -> persistant volumn claim : persistant volumn이라는 pv와 statefulset에 의해 형성되는 pod들이랑 **연결시켜주는 역할.** 

쿠버네티스 상에서 pod는 언제든 꺼지고 켜질 수 있는 존재. (컨테이너 배포의 장점은 유연한 배포가 장점). 그런데 pod에 중요한 DB정보를 저장하고 있었다면? DB pod를 껐다 켤 때 기존에 있던 DB 정보들이 날아갈 수 있음. 

statefulset은  그것 때문에 나타난 객체이고

persistant volumn은 volumn을 만들어서 영구적으로 데이터를 저장하는 객체를 만들고, pvc는 그것을 붙여주는 객체라고 보면 됨. 

`kubectl get pv`

---

**Kargo는 기본적으로 ‘목표 상태’에 ‘현재 상태’를 맞추기 위해서 쿠버네티스 자원을 생성해주는 역할을 한다.** 
